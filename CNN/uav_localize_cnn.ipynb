{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "uav_localize_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e4o1K6WKcev"
      },
      "source": [
        "Downloading data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iuJ4fzmuKc-U"
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "                \n",
        "                \n",
        "file_id = '1GMnPjRUju5YzZEWL5bk9qCrf90vXWEqD'\n",
        "destination = 'data_uav.zip'\n",
        "download_file_from_google_drive(file_id, destination)\n",
        "\n",
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('data_uav.zip', 'r') as zipObj:\n",
        "   # Extract all the contents of zip file in current directory\n",
        "   zipObj.extractall()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Paw6swN-O9Ga"
      },
      "source": [
        "Loading all the characteristics. 6 in total that are toa, zoa, zod aoa, aod, rxpower."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H4iDaSsKamx"
      },
      "source": [
        "\n",
        "import scipy.io\n",
        "import numpy as np\n",
        "\n",
        "num_trajs = 50\n",
        "n_bs = 4\n",
        "n_paths = 25\n",
        "n_time = 3e3\n",
        "n_features = 6\n",
        "\n",
        "mat = scipy.io.loadmat('all_azimuth_aoa_tensor_paths.mat')\n",
        "azimuth_aoa_tensor = mat['azimuth_aoa_tensor'] # dimensions are n_traj x n_time x n_bs x n_paths\n",
        "azimuth_aoa_tensor = np.reshape(azimuth_aoa_tensor,(int(num_trajs*n_time),n_bs,n_paths))\n",
        "\n",
        "\n",
        "mat = scipy.io.loadmat('all_azimuth_aod_tensor_paths.mat')\n",
        "azimuth_aod_tensor = mat['azimuth_aod_tensor'] # dimensions are n_traj x n_time x n_bs x n_paths\n",
        "azimuth_aod_tensor = np.reshape(azimuth_aod_tensor,(int(num_trajs*n_time),n_bs,n_paths))\n",
        "\n",
        "mat = scipy.io.loadmat('all_zenith_aod_tensor_paths.mat')\n",
        "zenith_aod_tensor = mat['zenith_aod_tensor'] # dimensions are n_traj x n_time x n_bs x n_paths\n",
        "zenith_aod_tensor = np.reshape(zenith_aod_tensor,(int(num_trajs*n_time),n_bs,n_paths))\n",
        "\n",
        "mat = scipy.io.loadmat('all_zenith_aoa_tensor_paths.mat')\n",
        "zenith_aoa_tensor = mat['zenith_aoa_tensor'] # dimensions are n_traj x n_time x n_bs x n_paths\n",
        "zenith_aoa_tensor = np.reshape(zenith_aoa_tensor,(int(num_trajs*n_time),n_bs,n_paths))\n",
        "\n",
        "\n",
        "mat = scipy.io.loadmat('all_rxpower_tensor_paths.mat')\n",
        "rx_power_tensor = mat['rx_power_tensor'] # dimensions are n_traj x n_time x n_bs x n_paths\n",
        "rx_power_tensor = np.reshape(rx_power_tensor,(int(num_trajs*n_time),n_bs,n_paths))\n",
        "rx_power_tensor = 10**(0.1*rx_power_tensor) # in Watts\n",
        "\n",
        "mat = scipy.io.loadmat('all_toa_tensor_paths.mat')\n",
        "toa_tensor = mat['toa_tensor'] # dimensions are n_traj x n_time x n_bs x n_paths\n",
        "toa_tensor = np.reshape(toa_tensor,(int(num_trajs*n_time),n_bs,n_paths))*1e3 #in ms\n",
        "\n",
        "\n",
        "mat = scipy.io.loadmat('all_true_tensor.mat')\n",
        "true_cord_tensor = mat['true_cord_tensor'] # dimensions are n_traj x n_time x 3\n",
        "true_cord_tensor = np.reshape(true_cord_tensor,(int(num_trajs*n_time),3))\n",
        "del mat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luOlJmYXKamz"
      },
      "source": [
        "**Constructing the input tensor with dimensions n_samples x n_bs x n_paths x n_features**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbZpm1r9Kamz",
        "outputId": "a2d6159c-2695-413b-bd5d-53c986ab482b"
      },
      "source": [
        "import math\n",
        "input_tensor = np.zeros((int(num_trajs*n_time),n_bs,n_paths,n_features))*math.nan\n",
        "\n",
        "n_samples = int(num_trajs*n_time)\n",
        "\n",
        "\n",
        "input_tensor[:,:,:,0] = azimuth_aoa_tensor\n",
        "del azimuth_aoa_tensor\n",
        "\n",
        "input_tensor[:,:,:,1] = azimuth_aod_tensor\n",
        "del azimuth_aod_tensor\n",
        "\n",
        "input_tensor[:,:,:,2] = zenith_aoa_tensor\n",
        "del zenith_aoa_tensor\n",
        "\n",
        "input_tensor[:,:,:,3] = zenith_aod_tensor\n",
        "del zenith_aod_tensor\n",
        "\n",
        "input_tensor[:,:,:,4] = rx_power_tensor\n",
        "del rx_power_tensor\n",
        "\n",
        "input_tensor[:,:,:,5] = toa_tensor\n",
        "del toa_tensor\n",
        "\n",
        "print(np.sum(np.isnan(input_tensor))) ## making sure that there are no values left unassigned"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PB4G7SUPWJh"
      },
      "source": [
        "Each input sample has a shape 4x25x6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjQN2SDQKam0",
        "outputId": "d521be44-48f9-4cea-d038-a74c90d6d9e5"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "inputShape = input_tensor.shape[1:]\n",
        "print(inputShape)\n",
        "#input_tensor = np.reshape(input_tensor,(n_samples,int(n_bs*n_paths*n_features)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4, 25, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "119h0zRkKam0"
      },
      "source": [
        "**CNN  approach**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aHrgVK2PaJT"
      },
      "source": [
        "Constructing CNN and declaring hyper-parameters. We tried batchnorm and dropout, it resulted in worse performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OU4jRtBfKam1",
        "outputId": "13ffd03a-d000-4bd1-99b1-18033f371305"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "input_tensor = input_tensor \n",
        "true_cord_tensor = true_cord_tensor - np.min(true_cord_tensor,axis = 0) ## assuming we know the minimum coordinates, done for stability of relu\n",
        "true_cord_tensor = true_cord_tensor\n",
        "\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(64, (7,7), padding=\"same\", input_shape=inputShape,activation=\"relu\",strides=1))\n",
        "#model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Conv2D(32, (5,5), padding=\"same\",activation=\"relu\",strides=1))\n",
        "#model.add(layers.Dropout(0.2))\n",
        "model.add(layers.Conv2D(16, (5,5), padding=\"same\",activation=\"relu\",strides=1))\n",
        "#model.add(layers.Conv2D(16, (5,5), padding=\"same\",activation=\"relu\",strides=1))\n",
        "#model.add(layers.Dropout(0.2))\n",
        "# model.add(layers.Conv2D(32, (3,3), padding=\"same\",activation=\"relu\"))\n",
        "# model.add(layers.Dropout(0.2))\n",
        "# model.add(layers.Conv2D(32, (3,3), padding=\"same\",activation=\"relu\"))\n",
        "# model.add(layers.Dropout(0.2))\n",
        "# model.add(layers.Conv2D(32, (5,5), padding=\"same\",activation=\"relu\"))\n",
        "# model.add(layers.Dropout(0.2))\n",
        "# model.add(layers.Conv2D(32, (5,5), padding=\"same\",activation=\"relu\"))\n",
        "# model.add(layers.Dropout(0.2))\n",
        "# model.add(layers.Conv2D(8, (3, 3), padding=\"same\",activation=\"relu\"))\n",
        "# model.add(layers.Dropout(0.2))\n",
        "#model.add(layers.Dense(64,activation = 'relu'))\n",
        "model.add(layers.Flatten())\n",
        "#model.add(layers.Dropout(0.2))\n",
        "# model.add(layers.Dense(16,activation = 'relu'))\n",
        "#model.add(layers.Dense(16,activation = 'relu'))\n",
        "model.add(layers.Dense(3,activation = 'relu'))\n",
        "print(model.summary())\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "model.compile(loss='mse', optimizer=opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 4, 25, 64)         18880     \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 4, 25, 32)         51232     \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 4, 25, 16)         12816     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 4803      \n",
            "=================================================================\n",
            "Total params: 87,731\n",
            "Trainable params: 87,731\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWIUaG4pPgpy"
      },
      "source": [
        "Training split. Preprocessing data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl4cmjGLKam1",
        "outputId": "02cb747d-1c1a-4dba-ea98-0b8e0cd873bc"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(np.reshape(input_tensor,(n_samples,int(n_bs*n_paths*n_features))), true_cord_tensor, test_size=0.5)\n",
        "\n",
        "\n",
        "scaler = preprocessing.StandardScaler() # pre processing data\n",
        "scaled_df = scaler.fit(X_train) \n",
        "scaled_df = scaler.transform(X_train)\n",
        "\n",
        "# outScaler = preprocessing.StandardScaler()\n",
        "# y_train_scaled = outScaler.fit(y_train)\n",
        "# y_train_scaled = outScaler.transform(y_train)\n",
        "\n",
        "scaled_df = np.reshape(scaled_df,(scaled_df.shape[0],n_bs,n_paths,n_features))\n",
        "print(scaled_df.shape)\n",
        "# print(np.min(y_train_scaled))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(75000, 4, 25, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5eecVjPPoRb"
      },
      "source": [
        "Running training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2DbjK2HKam2",
        "outputId": "e11e351b-c024-4067-97a5-c01a999f7160"
      },
      "source": [
        "model.fit(scaled_df,y_train, epochs=500, batch_size=32, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2344/2344 - 37s - loss: 1707.1338\n",
            "Epoch 2/500\n",
            "2344/2344 - 5s - loss: 103.1700\n",
            "Epoch 3/500\n",
            "2344/2344 - 5s - loss: 60.8429\n",
            "Epoch 4/500\n",
            "2344/2344 - 5s - loss: 43.9422\n",
            "Epoch 5/500\n",
            "2344/2344 - 5s - loss: 34.8095\n",
            "Epoch 6/500\n",
            "2344/2344 - 5s - loss: 28.5608\n",
            "Epoch 7/500\n",
            "2344/2344 - 5s - loss: 24.3685\n",
            "Epoch 8/500\n",
            "2344/2344 - 5s - loss: 21.0016\n",
            "Epoch 9/500\n",
            "2344/2344 - 5s - loss: 18.6847\n",
            "Epoch 10/500\n",
            "2344/2344 - 5s - loss: 16.5492\n",
            "Epoch 11/500\n",
            "2344/2344 - 5s - loss: 15.7403\n",
            "Epoch 12/500\n",
            "2344/2344 - 5s - loss: 13.6846\n",
            "Epoch 13/500\n",
            "2344/2344 - 5s - loss: 12.8049\n",
            "Epoch 14/500\n",
            "2344/2344 - 5s - loss: 12.2904\n",
            "Epoch 15/500\n",
            "2344/2344 - 5s - loss: 11.3986\n",
            "Epoch 16/500\n",
            "2344/2344 - 5s - loss: 10.6959\n",
            "Epoch 17/500\n",
            "2344/2344 - 5s - loss: 9.9938\n",
            "Epoch 18/500\n",
            "2344/2344 - 5s - loss: 9.7204\n",
            "Epoch 19/500\n",
            "2344/2344 - 5s - loss: 9.2446\n",
            "Epoch 20/500\n",
            "2344/2344 - 5s - loss: 8.7385\n",
            "Epoch 21/500\n",
            "2344/2344 - 5s - loss: 8.3322\n",
            "Epoch 22/500\n",
            "2344/2344 - 5s - loss: 8.1037\n",
            "Epoch 23/500\n",
            "2344/2344 - 5s - loss: 8.0213\n",
            "Epoch 24/500\n",
            "2344/2344 - 5s - loss: 7.2783\n",
            "Epoch 25/500\n",
            "2344/2344 - 5s - loss: 6.9035\n",
            "Epoch 26/500\n",
            "2344/2344 - 5s - loss: 6.8558\n",
            "Epoch 27/500\n",
            "2344/2344 - 5s - loss: 6.4257\n",
            "Epoch 28/500\n",
            "2344/2344 - 5s - loss: 6.3990\n",
            "Epoch 29/500\n",
            "2344/2344 - 5s - loss: 6.1348\n",
            "Epoch 30/500\n",
            "2344/2344 - 5s - loss: 6.0598\n",
            "Epoch 31/500\n",
            "2344/2344 - 5s - loss: 5.9052\n",
            "Epoch 32/500\n",
            "2344/2344 - 5s - loss: 5.7053\n",
            "Epoch 33/500\n",
            "2344/2344 - 5s - loss: 5.4025\n",
            "Epoch 34/500\n",
            "2344/2344 - 5s - loss: 5.6071\n",
            "Epoch 35/500\n",
            "2344/2344 - 5s - loss: 5.1088\n",
            "Epoch 36/500\n",
            "2344/2344 - 5s - loss: 5.1261\n",
            "Epoch 37/500\n",
            "2344/2344 - 5s - loss: 5.0597\n",
            "Epoch 38/500\n",
            "2344/2344 - 5s - loss: 4.8460\n",
            "Epoch 39/500\n",
            "2344/2344 - 5s - loss: 4.7087\n",
            "Epoch 40/500\n",
            "2344/2344 - 5s - loss: 4.4827\n",
            "Epoch 41/500\n",
            "2344/2344 - 5s - loss: 4.6987\n",
            "Epoch 42/500\n",
            "2344/2344 - 5s - loss: 4.3884\n",
            "Epoch 43/500\n",
            "2344/2344 - 5s - loss: 4.2930\n",
            "Epoch 44/500\n",
            "2344/2344 - 5s - loss: 4.2021\n",
            "Epoch 45/500\n",
            "2344/2344 - 5s - loss: 4.0286\n",
            "Epoch 46/500\n",
            "2344/2344 - 5s - loss: 4.1439\n",
            "Epoch 47/500\n",
            "2344/2344 - 5s - loss: 3.9913\n",
            "Epoch 48/500\n",
            "2344/2344 - 5s - loss: 4.0369\n",
            "Epoch 49/500\n",
            "2344/2344 - 5s - loss: 3.7874\n",
            "Epoch 50/500\n",
            "2344/2344 - 5s - loss: 3.7422\n",
            "Epoch 51/500\n",
            "2344/2344 - 5s - loss: 3.6749\n",
            "Epoch 52/500\n",
            "2344/2344 - 4s - loss: 3.6430\n",
            "Epoch 53/500\n",
            "2344/2344 - 4s - loss: 3.5916\n",
            "Epoch 54/500\n",
            "2344/2344 - 4s - loss: 3.4286\n",
            "Epoch 55/500\n",
            "2344/2344 - 5s - loss: 3.3109\n",
            "Epoch 56/500\n",
            "2344/2344 - 4s - loss: 3.4198\n",
            "Epoch 57/500\n",
            "2344/2344 - 4s - loss: 3.2882\n",
            "Epoch 58/500\n",
            "2344/2344 - 5s - loss: 3.2622\n",
            "Epoch 59/500\n",
            "2344/2344 - 5s - loss: 3.2533\n",
            "Epoch 60/500\n",
            "2344/2344 - 5s - loss: 3.2402\n",
            "Epoch 61/500\n",
            "2344/2344 - 5s - loss: 3.1889\n",
            "Epoch 62/500\n",
            "2344/2344 - 5s - loss: 3.0677\n",
            "Epoch 63/500\n",
            "2344/2344 - 4s - loss: 2.8770\n",
            "Epoch 64/500\n",
            "2344/2344 - 5s - loss: 3.0163\n",
            "Epoch 65/500\n",
            "2344/2344 - 5s - loss: 2.9984\n",
            "Epoch 66/500\n",
            "2344/2344 - 5s - loss: 2.8902\n",
            "Epoch 67/500\n",
            "2344/2344 - 5s - loss: 2.7854\n",
            "Epoch 68/500\n",
            "2344/2344 - 5s - loss: 2.8372\n",
            "Epoch 69/500\n",
            "2344/2344 - 4s - loss: 2.8121\n",
            "Epoch 70/500\n",
            "2344/2344 - 4s - loss: 2.7192\n",
            "Epoch 71/500\n",
            "2344/2344 - 5s - loss: 2.6374\n",
            "Epoch 72/500\n",
            "2344/2344 - 5s - loss: 2.6660\n",
            "Epoch 73/500\n",
            "2344/2344 - 5s - loss: 2.7207\n",
            "Epoch 74/500\n",
            "2344/2344 - 4s - loss: 2.5009\n",
            "Epoch 75/500\n",
            "2344/2344 - 4s - loss: 2.5104\n",
            "Epoch 76/500\n",
            "2344/2344 - 4s - loss: 2.6200\n",
            "Epoch 77/500\n",
            "2344/2344 - 4s - loss: 2.5241\n",
            "Epoch 78/500\n",
            "2344/2344 - 4s - loss: 2.4199\n",
            "Epoch 79/500\n",
            "2344/2344 - 5s - loss: 2.5324\n",
            "Epoch 80/500\n",
            "2344/2344 - 5s - loss: 2.3465\n",
            "Epoch 81/500\n",
            "2344/2344 - 4s - loss: 2.4096\n",
            "Epoch 82/500\n",
            "2344/2344 - 4s - loss: 2.4885\n",
            "Epoch 83/500\n",
            "2344/2344 - 5s - loss: 2.2876\n",
            "Epoch 84/500\n",
            "2344/2344 - 4s - loss: 2.2138\n",
            "Epoch 85/500\n",
            "2344/2344 - 4s - loss: 2.2781\n",
            "Epoch 86/500\n",
            "2344/2344 - 4s - loss: 2.3296\n",
            "Epoch 87/500\n",
            "2344/2344 - 4s - loss: 2.2573\n",
            "Epoch 88/500\n",
            "2344/2344 - 4s - loss: 2.1470\n",
            "Epoch 89/500\n",
            "2344/2344 - 4s - loss: 2.1989\n",
            "Epoch 90/500\n",
            "2344/2344 - 4s - loss: 2.1463\n",
            "Epoch 91/500\n",
            "2344/2344 - 4s - loss: 2.1319\n",
            "Epoch 92/500\n",
            "2344/2344 - 4s - loss: 2.1599\n",
            "Epoch 93/500\n",
            "2344/2344 - 4s - loss: 2.0420\n",
            "Epoch 94/500\n",
            "2344/2344 - 4s - loss: 2.0874\n",
            "Epoch 95/500\n",
            "2344/2344 - 4s - loss: 1.9816\n",
            "Epoch 96/500\n",
            "2344/2344 - 4s - loss: 2.0560\n",
            "Epoch 97/500\n",
            "2344/2344 - 4s - loss: 2.0208\n",
            "Epoch 98/500\n",
            "2344/2344 - 5s - loss: 1.8453\n",
            "Epoch 99/500\n",
            "2344/2344 - 4s - loss: 1.9472\n",
            "Epoch 100/500\n",
            "2344/2344 - 5s - loss: 1.9299\n",
            "Epoch 101/500\n",
            "2344/2344 - 5s - loss: 1.9094\n",
            "Epoch 102/500\n",
            "2344/2344 - 5s - loss: 1.8254\n",
            "Epoch 103/500\n",
            "2344/2344 - 4s - loss: 1.8500\n",
            "Epoch 104/500\n",
            "2344/2344 - 4s - loss: 1.8721\n",
            "Epoch 105/500\n",
            "2344/2344 - 4s - loss: 1.8206\n",
            "Epoch 106/500\n",
            "2344/2344 - 4s - loss: 1.7819\n",
            "Epoch 107/500\n",
            "2344/2344 - 4s - loss: 1.7525\n",
            "Epoch 108/500\n",
            "2344/2344 - 4s - loss: 1.7453\n",
            "Epoch 109/500\n",
            "2344/2344 - 4s - loss: 1.7677\n",
            "Epoch 110/500\n",
            "2344/2344 - 4s - loss: 1.7275\n",
            "Epoch 111/500\n",
            "2344/2344 - 4s - loss: 1.6872\n",
            "Epoch 112/500\n",
            "2344/2344 - 4s - loss: 1.7160\n",
            "Epoch 113/500\n",
            "2344/2344 - 4s - loss: 1.6794\n",
            "Epoch 114/500\n",
            "2344/2344 - 4s - loss: 1.6505\n",
            "Epoch 115/500\n",
            "2344/2344 - 4s - loss: 1.7548\n",
            "Epoch 116/500\n",
            "2344/2344 - 4s - loss: 1.6001\n",
            "Epoch 117/500\n",
            "2344/2344 - 4s - loss: 1.6033\n",
            "Epoch 118/500\n",
            "2344/2344 - 4s - loss: 1.5638\n",
            "Epoch 119/500\n",
            "2344/2344 - 5s - loss: 1.5867\n",
            "Epoch 120/500\n",
            "2344/2344 - 5s - loss: 1.5363\n",
            "Epoch 121/500\n",
            "2344/2344 - 4s - loss: 1.5920\n",
            "Epoch 122/500\n",
            "2344/2344 - 4s - loss: 1.5602\n",
            "Epoch 123/500\n",
            "2344/2344 - 4s - loss: 1.5411\n",
            "Epoch 124/500\n",
            "2344/2344 - 4s - loss: 1.5370\n",
            "Epoch 125/500\n",
            "2344/2344 - 4s - loss: 1.5080\n",
            "Epoch 126/500\n",
            "2344/2344 - 4s - loss: 1.4366\n",
            "Epoch 127/500\n",
            "2344/2344 - 4s - loss: 1.4722\n",
            "Epoch 128/500\n",
            "2344/2344 - 5s - loss: 1.5518\n",
            "Epoch 129/500\n",
            "2344/2344 - 4s - loss: 1.4336\n",
            "Epoch 130/500\n",
            "2344/2344 - 5s - loss: 1.4076\n",
            "Epoch 131/500\n",
            "2344/2344 - 4s - loss: 1.3952\n",
            "Epoch 132/500\n",
            "2344/2344 - 4s - loss: 1.4111\n",
            "Epoch 133/500\n",
            "2344/2344 - 4s - loss: 1.3862\n",
            "Epoch 134/500\n",
            "2344/2344 - 4s - loss: 1.3909\n",
            "Epoch 135/500\n",
            "2344/2344 - 4s - loss: 1.3797\n",
            "Epoch 136/500\n",
            "2344/2344 - 4s - loss: 1.3510\n",
            "Epoch 137/500\n",
            "2344/2344 - 4s - loss: 1.3489\n",
            "Epoch 138/500\n",
            "2344/2344 - 5s - loss: 1.3833\n",
            "Epoch 139/500\n",
            "2344/2344 - 4s - loss: 1.3298\n",
            "Epoch 140/500\n",
            "2344/2344 - 4s - loss: 1.3153\n",
            "Epoch 141/500\n",
            "2344/2344 - 4s - loss: 1.3269\n",
            "Epoch 142/500\n",
            "2344/2344 - 4s - loss: 1.2791\n",
            "Epoch 143/500\n",
            "2344/2344 - 4s - loss: 1.3213\n",
            "Epoch 144/500\n",
            "2344/2344 - 4s - loss: 1.2649\n",
            "Epoch 145/500\n",
            "2344/2344 - 4s - loss: 1.2986\n",
            "Epoch 146/500\n",
            "2344/2344 - 4s - loss: 1.2656\n",
            "Epoch 147/500\n",
            "2344/2344 - 4s - loss: 1.2206\n",
            "Epoch 148/500\n",
            "2344/2344 - 5s - loss: 1.2411\n",
            "Epoch 149/500\n",
            "2344/2344 - 4s - loss: 1.1951\n",
            "Epoch 150/500\n",
            "2344/2344 - 4s - loss: 1.2751\n",
            "Epoch 151/500\n",
            "2344/2344 - 4s - loss: 1.1789\n",
            "Epoch 152/500\n",
            "2344/2344 - 4s - loss: 1.1881\n",
            "Epoch 153/500\n",
            "2344/2344 - 4s - loss: 1.1984\n",
            "Epoch 154/500\n",
            "2344/2344 - 4s - loss: 1.3381\n",
            "Epoch 155/500\n",
            "2344/2344 - 5s - loss: 1.1244\n",
            "Epoch 156/500\n",
            "2344/2344 - 5s - loss: 1.1302\n",
            "Epoch 157/500\n",
            "2344/2344 - 4s - loss: 1.0894\n",
            "Epoch 158/500\n",
            "2344/2344 - 4s - loss: 1.2647\n",
            "Epoch 159/500\n",
            "2344/2344 - 4s - loss: 1.1182\n",
            "Epoch 160/500\n",
            "2344/2344 - 4s - loss: 1.1498\n",
            "Epoch 161/500\n",
            "2344/2344 - 4s - loss: 1.0714\n",
            "Epoch 162/500\n",
            "2344/2344 - 4s - loss: 1.0659\n",
            "Epoch 163/500\n",
            "2344/2344 - 4s - loss: 1.1059\n",
            "Epoch 164/500\n",
            "2344/2344 - 4s - loss: 1.0581\n",
            "Epoch 165/500\n",
            "2344/2344 - 4s - loss: 1.1489\n",
            "Epoch 166/500\n",
            "2344/2344 - 4s - loss: 1.0939\n",
            "Epoch 167/500\n",
            "2344/2344 - 4s - loss: 1.0733\n",
            "Epoch 168/500\n",
            "2344/2344 - 4s - loss: 0.9783\n",
            "Epoch 169/500\n",
            "2344/2344 - 4s - loss: 1.1223\n",
            "Epoch 170/500\n",
            "2344/2344 - 4s - loss: 1.0456\n",
            "Epoch 171/500\n",
            "2344/2344 - 4s - loss: 1.1094\n",
            "Epoch 172/500\n",
            "2344/2344 - 4s - loss: 0.9836\n",
            "Epoch 173/500\n",
            "2344/2344 - 4s - loss: 0.9813\n",
            "Epoch 174/500\n",
            "2344/2344 - 5s - loss: 1.0740\n",
            "Epoch 175/500\n",
            "2344/2344 - 5s - loss: 1.0095\n",
            "Epoch 176/500\n",
            "2344/2344 - 5s - loss: 1.0614\n",
            "Epoch 177/500\n",
            "2344/2344 - 4s - loss: 0.9752\n",
            "Epoch 178/500\n",
            "2344/2344 - 4s - loss: 0.9634\n",
            "Epoch 179/500\n",
            "2344/2344 - 4s - loss: 0.9833\n",
            "Epoch 180/500\n",
            "2344/2344 - 4s - loss: 0.9520\n",
            "Epoch 181/500\n",
            "2344/2344 - 4s - loss: 0.9416\n",
            "Epoch 182/500\n",
            "2344/2344 - 5s - loss: 0.9552\n",
            "Epoch 183/500\n",
            "2344/2344 - 4s - loss: 0.9346\n",
            "Epoch 184/500\n",
            "2344/2344 - 4s - loss: 0.9156\n",
            "Epoch 185/500\n",
            "2344/2344 - 4s - loss: 0.9179\n",
            "Epoch 186/500\n",
            "2344/2344 - 4s - loss: 0.9382\n",
            "Epoch 187/500\n",
            "2344/2344 - 4s - loss: 0.9134\n",
            "Epoch 188/500\n",
            "2344/2344 - 4s - loss: 0.9605\n",
            "Epoch 189/500\n",
            "2344/2344 - 4s - loss: 0.9235\n",
            "Epoch 190/500\n",
            "2344/2344 - 4s - loss: 0.9103\n",
            "Epoch 191/500\n",
            "2344/2344 - 5s - loss: 0.9043\n",
            "Epoch 192/500\n",
            "2344/2344 - 5s - loss: 0.9199\n",
            "Epoch 193/500\n",
            "2344/2344 - 4s - loss: 0.9001\n",
            "Epoch 194/500\n",
            "2344/2344 - 4s - loss: 0.8764\n",
            "Epoch 195/500\n",
            "2344/2344 - 4s - loss: 0.9157\n",
            "Epoch 196/500\n",
            "2344/2344 - 4s - loss: 0.9053\n",
            "Epoch 197/500\n",
            "2344/2344 - 5s - loss: 0.8297\n",
            "Epoch 198/500\n",
            "2344/2344 - 5s - loss: 0.8446\n",
            "Epoch 199/500\n",
            "2344/2344 - 5s - loss: 0.8429\n",
            "Epoch 200/500\n",
            "2344/2344 - 4s - loss: 0.8391\n",
            "Epoch 201/500\n",
            "2344/2344 - 4s - loss: 0.8317\n",
            "Epoch 202/500\n",
            "2344/2344 - 4s - loss: 0.8384\n",
            "Epoch 203/500\n",
            "2344/2344 - 4s - loss: 0.7986\n",
            "Epoch 204/500\n",
            "2344/2344 - 4s - loss: 0.8139\n",
            "Epoch 205/500\n",
            "2344/2344 - 4s - loss: 0.8672\n",
            "Epoch 206/500\n",
            "2344/2344 - 4s - loss: 0.8425\n",
            "Epoch 207/500\n",
            "2344/2344 - 4s - loss: 0.8191\n",
            "Epoch 208/500\n",
            "2344/2344 - 4s - loss: 0.8355\n",
            "Epoch 209/500\n",
            "2344/2344 - 5s - loss: 0.7652\n",
            "Epoch 210/500\n",
            "2344/2344 - 5s - loss: 0.8271\n",
            "Epoch 211/500\n",
            "2344/2344 - 5s - loss: 0.7752\n",
            "Epoch 212/500\n",
            "2344/2344 - 4s - loss: 0.7923\n",
            "Epoch 213/500\n",
            "2344/2344 - 4s - loss: 0.7700\n",
            "Epoch 214/500\n",
            "2344/2344 - 4s - loss: 0.7703\n",
            "Epoch 215/500\n",
            "2344/2344 - 4s - loss: 0.7839\n",
            "Epoch 216/500\n",
            "2344/2344 - 5s - loss: 0.7972\n",
            "Epoch 217/500\n",
            "2344/2344 - 4s - loss: 0.7720\n",
            "Epoch 218/500\n",
            "2344/2344 - 4s - loss: 0.7509\n",
            "Epoch 219/500\n",
            "2344/2344 - 4s - loss: 0.7592\n",
            "Epoch 220/500\n",
            "2344/2344 - 4s - loss: 0.7552\n",
            "Epoch 221/500\n",
            "2344/2344 - 4s - loss: 0.7852\n",
            "Epoch 222/500\n",
            "2344/2344 - 4s - loss: 0.7146\n",
            "Epoch 223/500\n",
            "2344/2344 - 4s - loss: 0.7688\n",
            "Epoch 224/500\n",
            "2344/2344 - 4s - loss: 0.7600\n",
            "Epoch 225/500\n",
            "2344/2344 - 4s - loss: 0.7615\n",
            "Epoch 226/500\n",
            "2344/2344 - 4s - loss: 0.7132\n",
            "Epoch 227/500\n",
            "2344/2344 - 4s - loss: 0.7081\n",
            "Epoch 228/500\n",
            "2344/2344 - 4s - loss: 0.7252\n",
            "Epoch 229/500\n",
            "2344/2344 - 5s - loss: 0.7165\n",
            "Epoch 230/500\n",
            "2344/2344 - 4s - loss: 0.7147\n",
            "Epoch 231/500\n",
            "2344/2344 - 4s - loss: 0.7169\n",
            "Epoch 232/500\n",
            "2344/2344 - 4s - loss: 0.6827\n",
            "Epoch 233/500\n",
            "2344/2344 - 4s - loss: 0.6902\n",
            "Epoch 234/500\n",
            "2344/2344 - 4s - loss: 0.6831\n",
            "Epoch 235/500\n",
            "2344/2344 - 4s - loss: 0.7190\n",
            "Epoch 236/500\n",
            "2344/2344 - 4s - loss: 0.7036\n",
            "Epoch 237/500\n",
            "2344/2344 - 5s - loss: 0.6889\n",
            "Epoch 238/500\n",
            "2344/2344 - 5s - loss: 0.6715\n",
            "Epoch 239/500\n",
            "2344/2344 - 5s - loss: 0.6498\n",
            "Epoch 240/500\n",
            "2344/2344 - 5s - loss: 0.6666\n",
            "Epoch 241/500\n",
            "2344/2344 - 4s - loss: 0.7076\n",
            "Epoch 242/500\n",
            "2344/2344 - 5s - loss: 0.6697\n",
            "Epoch 243/500\n",
            "2344/2344 - 5s - loss: 0.6719\n",
            "Epoch 244/500\n",
            "2344/2344 - 5s - loss: 0.6666\n",
            "Epoch 245/500\n",
            "2344/2344 - 5s - loss: 0.6259\n",
            "Epoch 246/500\n",
            "2344/2344 - 5s - loss: 0.6484\n",
            "Epoch 247/500\n",
            "2344/2344 - 5s - loss: 0.6885\n",
            "Epoch 248/500\n",
            "2344/2344 - 5s - loss: 0.6371\n",
            "Epoch 249/500\n",
            "2344/2344 - 5s - loss: 0.6695\n",
            "Epoch 250/500\n",
            "2344/2344 - 5s - loss: 0.5959\n",
            "Epoch 251/500\n",
            "2344/2344 - 5s - loss: 0.6482\n",
            "Epoch 252/500\n",
            "2344/2344 - 5s - loss: 0.6409\n",
            "Epoch 253/500\n",
            "2344/2344 - 5s - loss: 0.5910\n",
            "Epoch 254/500\n",
            "2344/2344 - 4s - loss: 0.6322\n",
            "Epoch 255/500\n",
            "2344/2344 - 5s - loss: 0.5793\n",
            "Epoch 256/500\n",
            "2344/2344 - 4s - loss: 0.6336\n",
            "Epoch 257/500\n",
            "2344/2344 - 5s - loss: 0.6493\n",
            "Epoch 258/500\n",
            "2344/2344 - 5s - loss: 0.6235\n",
            "Epoch 259/500\n",
            "2344/2344 - 5s - loss: 0.6360\n",
            "Epoch 260/500\n",
            "2344/2344 - 5s - loss: 0.5961\n",
            "Epoch 261/500\n",
            "2344/2344 - 5s - loss: 0.6016\n",
            "Epoch 262/500\n",
            "2344/2344 - 5s - loss: 0.5898\n",
            "Epoch 263/500\n",
            "2344/2344 - 5s - loss: 0.6147\n",
            "Epoch 264/500\n",
            "2344/2344 - 5s - loss: 0.6221\n",
            "Epoch 265/500\n",
            "2344/2344 - 5s - loss: 0.5702\n",
            "Epoch 266/500\n",
            "2344/2344 - 5s - loss: 0.5815\n",
            "Epoch 267/500\n",
            "2344/2344 - 5s - loss: 0.5758\n",
            "Epoch 268/500\n",
            "2344/2344 - 5s - loss: 0.5864\n",
            "Epoch 269/500\n",
            "2344/2344 - 5s - loss: 0.6050\n",
            "Epoch 270/500\n",
            "2344/2344 - 5s - loss: 0.5930\n",
            "Epoch 271/500\n",
            "2344/2344 - 5s - loss: 0.5725\n",
            "Epoch 272/500\n",
            "2344/2344 - 5s - loss: 0.5789\n",
            "Epoch 273/500\n",
            "2344/2344 - 5s - loss: 0.6272\n",
            "Epoch 274/500\n",
            "2344/2344 - 5s - loss: 0.5547\n",
            "Epoch 275/500\n",
            "2344/2344 - 5s - loss: 0.5282\n",
            "Epoch 276/500\n",
            "2344/2344 - 5s - loss: 0.5518\n",
            "Epoch 277/500\n",
            "2344/2344 - 5s - loss: 0.5396\n",
            "Epoch 278/500\n",
            "2344/2344 - 5s - loss: 0.5898\n",
            "Epoch 279/500\n",
            "2344/2344 - 5s - loss: 0.5216\n",
            "Epoch 280/500\n",
            "2344/2344 - 5s - loss: 0.5713\n",
            "Epoch 281/500\n",
            "2344/2344 - 5s - loss: 0.5501\n",
            "Epoch 282/500\n",
            "2344/2344 - 5s - loss: 0.5299\n",
            "Epoch 283/500\n",
            "2344/2344 - 5s - loss: 0.5283\n",
            "Epoch 284/500\n",
            "2344/2344 - 5s - loss: 0.5680\n",
            "Epoch 285/500\n",
            "2344/2344 - 5s - loss: 0.5257\n",
            "Epoch 286/500\n",
            "2344/2344 - 5s - loss: 0.5549\n",
            "Epoch 287/500\n",
            "2344/2344 - 5s - loss: 0.5458\n",
            "Epoch 288/500\n",
            "2344/2344 - 5s - loss: 0.5131\n",
            "Epoch 289/500\n",
            "2344/2344 - 5s - loss: 0.5290\n",
            "Epoch 290/500\n",
            "2344/2344 - 4s - loss: 0.5215\n",
            "Epoch 291/500\n",
            "2344/2344 - 5s - loss: 0.5568\n",
            "Epoch 292/500\n",
            "2344/2344 - 5s - loss: 0.5320\n",
            "Epoch 293/500\n",
            "2344/2344 - 4s - loss: 0.5502\n",
            "Epoch 294/500\n",
            "2344/2344 - 4s - loss: 0.4847\n",
            "Epoch 295/500\n",
            "2344/2344 - 4s - loss: 0.5375\n",
            "Epoch 296/500\n",
            "2344/2344 - 4s - loss: 0.5297\n",
            "Epoch 297/500\n",
            "2344/2344 - 5s - loss: 0.5167\n",
            "Epoch 298/500\n",
            "2344/2344 - 5s - loss: 0.4981\n",
            "Epoch 299/500\n",
            "2344/2344 - 5s - loss: 0.5066\n",
            "Epoch 300/500\n",
            "2344/2344 - 5s - loss: 0.4882\n",
            "Epoch 301/500\n",
            "2344/2344 - 4s - loss: 0.5225\n",
            "Epoch 302/500\n",
            "2344/2344 - 4s - loss: 0.5049\n",
            "Epoch 303/500\n",
            "2344/2344 - 4s - loss: 0.4801\n",
            "Epoch 304/500\n",
            "2344/2344 - 4s - loss: 0.5199\n",
            "Epoch 305/500\n",
            "2344/2344 - 4s - loss: 0.4859\n",
            "Epoch 306/500\n",
            "2344/2344 - 4s - loss: 0.5414\n",
            "Epoch 307/500\n",
            "2344/2344 - 4s - loss: 0.4715\n",
            "Epoch 308/500\n",
            "2344/2344 - 4s - loss: 0.4840\n",
            "Epoch 309/500\n",
            "2344/2344 - 4s - loss: 0.5031\n",
            "Epoch 310/500\n",
            "2344/2344 - 4s - loss: 0.4774\n",
            "Epoch 311/500\n",
            "2344/2344 - 4s - loss: 0.4873\n",
            "Epoch 312/500\n",
            "2344/2344 - 4s - loss: 0.4425\n",
            "Epoch 313/500\n",
            "2344/2344 - 4s - loss: 0.4986\n",
            "Epoch 314/500\n",
            "2344/2344 - 4s - loss: 0.5175\n",
            "Epoch 315/500\n",
            "2344/2344 - 4s - loss: 0.4732\n",
            "Epoch 316/500\n",
            "2344/2344 - 4s - loss: 0.4802\n",
            "Epoch 317/500\n",
            "2344/2344 - 4s - loss: 0.5028\n",
            "Epoch 318/500\n",
            "2344/2344 - 4s - loss: 0.4583\n",
            "Epoch 319/500\n",
            "2344/2344 - 4s - loss: 0.4771\n",
            "Epoch 320/500\n",
            "2344/2344 - 4s - loss: 0.4648\n",
            "Epoch 321/500\n",
            "2344/2344 - 4s - loss: 0.4828\n",
            "Epoch 322/500\n",
            "2344/2344 - 4s - loss: 0.4816\n",
            "Epoch 323/500\n",
            "2344/2344 - 4s - loss: 0.4412\n",
            "Epoch 324/500\n",
            "2344/2344 - 4s - loss: 0.4629\n",
            "Epoch 325/500\n",
            "2344/2344 - 4s - loss: 0.4569\n",
            "Epoch 326/500\n",
            "2344/2344 - 4s - loss: 0.4485\n",
            "Epoch 327/500\n",
            "2344/2344 - 4s - loss: 0.4699\n",
            "Epoch 328/500\n",
            "2344/2344 - 4s - loss: 0.4295\n",
            "Epoch 329/500\n",
            "2344/2344 - 4s - loss: 0.4358\n",
            "Epoch 330/500\n",
            "2344/2344 - 4s - loss: 0.4704\n",
            "Epoch 331/500\n",
            "2344/2344 - 5s - loss: 0.4210\n",
            "Epoch 332/500\n",
            "2344/2344 - 4s - loss: 0.4676\n",
            "Epoch 333/500\n",
            "2344/2344 - 4s - loss: 0.4383\n",
            "Epoch 334/500\n",
            "2344/2344 - 5s - loss: 0.4095\n",
            "Epoch 335/500\n",
            "2344/2344 - 5s - loss: 0.4287\n",
            "Epoch 336/500\n",
            "2344/2344 - 5s - loss: 0.4519\n",
            "Epoch 337/500\n",
            "2344/2344 - 4s - loss: 0.4108\n",
            "Epoch 338/500\n",
            "2344/2344 - 4s - loss: 0.4578\n",
            "Epoch 339/500\n",
            "2344/2344 - 4s - loss: 0.4276\n",
            "Epoch 340/500\n",
            "2344/2344 - 4s - loss: 0.4314\n",
            "Epoch 341/500\n",
            "2344/2344 - 4s - loss: 0.4460\n",
            "Epoch 342/500\n",
            "2344/2344 - 4s - loss: 0.4402\n",
            "Epoch 343/500\n",
            "2344/2344 - 4s - loss: 0.4490\n",
            "Epoch 344/500\n",
            "2344/2344 - 5s - loss: 0.4117\n",
            "Epoch 345/500\n",
            "2344/2344 - 4s - loss: 0.4161\n",
            "Epoch 346/500\n",
            "2344/2344 - 4s - loss: 0.4301\n",
            "Epoch 347/500\n",
            "2344/2344 - 4s - loss: 0.4370\n",
            "Epoch 348/500\n",
            "2344/2344 - 4s - loss: 0.3807\n",
            "Epoch 349/500\n",
            "2344/2344 - 4s - loss: 0.4394\n",
            "Epoch 350/500\n",
            "2344/2344 - 4s - loss: 0.4723\n",
            "Epoch 351/500\n",
            "2344/2344 - 5s - loss: 0.4414\n",
            "Epoch 352/500\n",
            "2344/2344 - 5s - loss: 0.3982\n",
            "Epoch 353/500\n",
            "2344/2344 - 5s - loss: 0.4010\n",
            "Epoch 354/500\n",
            "2344/2344 - 4s - loss: 0.4916\n",
            "Epoch 355/500\n",
            "2344/2344 - 4s - loss: 0.4001\n",
            "Epoch 356/500\n",
            "2344/2344 - 4s - loss: 0.4033\n",
            "Epoch 357/500\n",
            "2344/2344 - 4s - loss: 0.4257\n",
            "Epoch 358/500\n",
            "2344/2344 - 4s - loss: 0.4264\n",
            "Epoch 359/500\n",
            "2344/2344 - 4s - loss: 0.3976\n",
            "Epoch 360/500\n",
            "2344/2344 - 4s - loss: 0.4248\n",
            "Epoch 361/500\n",
            "2344/2344 - 5s - loss: 0.4256\n",
            "Epoch 362/500\n",
            "2344/2344 - 4s - loss: 0.3745\n",
            "Epoch 363/500\n",
            "2344/2344 - 4s - loss: 0.3992\n",
            "Epoch 364/500\n",
            "2344/2344 - 4s - loss: 0.3845\n",
            "Epoch 365/500\n",
            "2344/2344 - 4s - loss: 0.3985\n",
            "Epoch 366/500\n",
            "2344/2344 - 4s - loss: 0.4762\n",
            "Epoch 367/500\n",
            "2344/2344 - 4s - loss: 0.3615\n",
            "Epoch 368/500\n",
            "2344/2344 - 4s - loss: 0.4256\n",
            "Epoch 369/500\n",
            "2344/2344 - 4s - loss: 0.3852\n",
            "Epoch 370/500\n",
            "2344/2344 - 5s - loss: 0.4050\n",
            "Epoch 371/500\n",
            "2344/2344 - 5s - loss: 0.3878\n",
            "Epoch 372/500\n",
            "2344/2344 - 4s - loss: 0.3827\n",
            "Epoch 373/500\n",
            "2344/2344 - 5s - loss: 0.3822\n",
            "Epoch 374/500\n",
            "2344/2344 - 4s - loss: 0.4004\n",
            "Epoch 375/500\n",
            "2344/2344 - 5s - loss: 0.4073\n",
            "Epoch 376/500\n",
            "2344/2344 - 4s - loss: 0.4005\n",
            "Epoch 377/500\n",
            "2344/2344 - 4s - loss: 0.3787\n",
            "Epoch 378/500\n",
            "2344/2344 - 4s - loss: 0.3594\n",
            "Epoch 379/500\n",
            "2344/2344 - 4s - loss: 0.3652\n",
            "Epoch 380/500\n",
            "2344/2344 - 4s - loss: 0.3875\n",
            "Epoch 381/500\n",
            "2344/2344 - 4s - loss: 0.3882\n",
            "Epoch 382/500\n",
            "2344/2344 - 4s - loss: 0.3996\n",
            "Epoch 383/500\n",
            "2344/2344 - 4s - loss: 0.3782\n",
            "Epoch 384/500\n",
            "2344/2344 - 4s - loss: 0.4029\n",
            "Epoch 385/500\n",
            "2344/2344 - 4s - loss: 0.3759\n",
            "Epoch 386/500\n",
            "2344/2344 - 4s - loss: 0.3752\n",
            "Epoch 387/500\n",
            "2344/2344 - 4s - loss: 0.3982\n",
            "Epoch 388/500\n",
            "2344/2344 - 5s - loss: 0.3980\n",
            "Epoch 389/500\n",
            "2344/2344 - 5s - loss: 0.3802\n",
            "Epoch 390/500\n",
            "2344/2344 - 4s - loss: 0.3833\n",
            "Epoch 391/500\n",
            "2344/2344 - 4s - loss: 0.3530\n",
            "Epoch 392/500\n",
            "2344/2344 - 4s - loss: 0.3796\n",
            "Epoch 393/500\n",
            "2344/2344 - 4s - loss: 0.3573\n",
            "Epoch 394/500\n",
            "2344/2344 - 4s - loss: 0.3765\n",
            "Epoch 395/500\n",
            "2344/2344 - 4s - loss: 0.3956\n",
            "Epoch 396/500\n",
            "2344/2344 - 4s - loss: 0.3629\n",
            "Epoch 397/500\n",
            "2344/2344 - 4s - loss: 0.3730\n",
            "Epoch 398/500\n",
            "2344/2344 - 4s - loss: 0.3799\n",
            "Epoch 399/500\n",
            "2344/2344 - 4s - loss: 0.3483\n",
            "Epoch 400/500\n",
            "2344/2344 - 4s - loss: 0.3543\n",
            "Epoch 401/500\n",
            "2344/2344 - 4s - loss: 0.3641\n",
            "Epoch 402/500\n",
            "2344/2344 - 4s - loss: 0.3549\n",
            "Epoch 403/500\n",
            "2344/2344 - 5s - loss: 0.3737\n",
            "Epoch 404/500\n",
            "2344/2344 - 4s - loss: 0.3585\n",
            "Epoch 405/500\n",
            "2344/2344 - 4s - loss: 0.3469\n",
            "Epoch 406/500\n",
            "2344/2344 - 4s - loss: 0.3540\n",
            "Epoch 407/500\n",
            "2344/2344 - 5s - loss: 0.3621\n",
            "Epoch 408/500\n",
            "2344/2344 - 4s - loss: 0.3702\n",
            "Epoch 409/500\n",
            "2344/2344 - 4s - loss: 0.3420\n",
            "Epoch 410/500\n",
            "2344/2344 - 4s - loss: 0.3560\n",
            "Epoch 411/500\n",
            "2344/2344 - 4s - loss: 0.3680\n",
            "Epoch 412/500\n",
            "2344/2344 - 4s - loss: 0.3243\n",
            "Epoch 413/500\n",
            "2344/2344 - 4s - loss: 0.3737\n",
            "Epoch 414/500\n",
            "2344/2344 - 4s - loss: 0.3423\n",
            "Epoch 415/500\n",
            "2344/2344 - 4s - loss: 0.3765\n",
            "Epoch 416/500\n",
            "2344/2344 - 5s - loss: 0.3188\n",
            "Epoch 417/500\n",
            "2344/2344 - 4s - loss: 0.3391\n",
            "Epoch 418/500\n",
            "2344/2344 - 4s - loss: 0.3723\n",
            "Epoch 419/500\n",
            "2344/2344 - 5s - loss: 0.3393\n",
            "Epoch 420/500\n",
            "2344/2344 - 5s - loss: 0.3567\n",
            "Epoch 421/500\n",
            "2344/2344 - 5s - loss: 0.4058\n",
            "Epoch 422/500\n",
            "2344/2344 - 5s - loss: 0.3085\n",
            "Epoch 423/500\n",
            "2344/2344 - 5s - loss: 0.3359\n",
            "Epoch 424/500\n",
            "2344/2344 - 5s - loss: 0.3178\n",
            "Epoch 425/500\n",
            "2344/2344 - 5s - loss: 0.3230\n",
            "Epoch 426/500\n",
            "2344/2344 - 5s - loss: 0.3057\n",
            "Epoch 427/500\n",
            "2344/2344 - 4s - loss: 0.3627\n",
            "Epoch 428/500\n",
            "2344/2344 - 4s - loss: 0.3124\n",
            "Epoch 429/500\n",
            "2344/2344 - 5s - loss: 0.3731\n",
            "Epoch 430/500\n",
            "2344/2344 - 4s - loss: 0.3532\n",
            "Epoch 431/500\n",
            "2344/2344 - 4s - loss: 0.3286\n",
            "Epoch 432/500\n",
            "2344/2344 - 4s - loss: 0.3331\n",
            "Epoch 433/500\n",
            "2344/2344 - 4s - loss: 0.3127\n",
            "Epoch 434/500\n",
            "2344/2344 - 4s - loss: 0.3473\n",
            "Epoch 435/500\n",
            "2344/2344 - 4s - loss: 0.3091\n",
            "Epoch 436/500\n",
            "2344/2344 - 4s - loss: 0.3467\n",
            "Epoch 437/500\n",
            "2344/2344 - 4s - loss: 0.3154\n",
            "Epoch 438/500\n",
            "2344/2344 - 4s - loss: 0.3230\n",
            "Epoch 439/500\n",
            "2344/2344 - 4s - loss: 0.3245\n",
            "Epoch 440/500\n",
            "2344/2344 - 4s - loss: 0.3510\n",
            "Epoch 441/500\n",
            "2344/2344 - 5s - loss: 0.3276\n",
            "Epoch 442/500\n",
            "2344/2344 - 5s - loss: 0.3072\n",
            "Epoch 443/500\n",
            "2344/2344 - 5s - loss: 0.2978\n",
            "Epoch 444/500\n",
            "2344/2344 - 4s - loss: 0.3449\n",
            "Epoch 445/500\n",
            "2344/2344 - 4s - loss: 0.3267\n",
            "Epoch 446/500\n",
            "2344/2344 - 4s - loss: 0.3319\n",
            "Epoch 447/500\n",
            "2344/2344 - 4s - loss: 0.3261\n",
            "Epoch 448/500\n",
            "2344/2344 - 4s - loss: 0.3066\n",
            "Epoch 449/500\n",
            "2344/2344 - 4s - loss: 0.3295\n",
            "Epoch 450/500\n",
            "2344/2344 - 4s - loss: 0.3200\n",
            "Epoch 451/500\n",
            "2344/2344 - 5s - loss: 0.3489\n",
            "Epoch 452/500\n",
            "2344/2344 - 4s - loss: 0.2995\n",
            "Epoch 453/500\n",
            "2344/2344 - 4s - loss: 0.3190\n",
            "Epoch 454/500\n",
            "2344/2344 - 4s - loss: 0.3062\n",
            "Epoch 455/500\n",
            "2344/2344 - 4s - loss: 0.3089\n",
            "Epoch 456/500\n",
            "2344/2344 - 4s - loss: 0.3234\n",
            "Epoch 457/500\n",
            "2344/2344 - 4s - loss: 0.2921\n",
            "Epoch 458/500\n",
            "2344/2344 - 4s - loss: 0.3130\n",
            "Epoch 459/500\n",
            "2344/2344 - 4s - loss: 0.3116\n",
            "Epoch 460/500\n",
            "2344/2344 - 4s - loss: 0.3052\n",
            "Epoch 461/500\n",
            "2344/2344 - 5s - loss: 0.3097\n",
            "Epoch 462/500\n",
            "2344/2344 - 5s - loss: 0.3076\n",
            "Epoch 463/500\n",
            "2344/2344 - 4s - loss: 0.3344\n",
            "Epoch 464/500\n",
            "2344/2344 - 4s - loss: 0.3177\n",
            "Epoch 465/500\n",
            "2344/2344 - 4s - loss: 0.3267\n",
            "Epoch 466/500\n",
            "2344/2344 - 4s - loss: 0.2809\n",
            "Epoch 467/500\n",
            "2344/2344 - 4s - loss: 0.3125\n",
            "Epoch 468/500\n",
            "2344/2344 - 4s - loss: 0.3153\n",
            "Epoch 469/500\n",
            "2344/2344 - 4s - loss: 0.2993\n",
            "Epoch 470/500\n",
            "2344/2344 - 4s - loss: 0.3013\n",
            "Epoch 471/500\n",
            "2344/2344 - 4s - loss: 0.2926\n",
            "Epoch 472/500\n",
            "2344/2344 - 5s - loss: 0.3005\n",
            "Epoch 473/500\n",
            "2344/2344 - 4s - loss: 0.3083\n",
            "Epoch 474/500\n",
            "2344/2344 - 5s - loss: 0.3039\n",
            "Epoch 475/500\n",
            "2344/2344 - 4s - loss: 0.2975\n",
            "Epoch 476/500\n",
            "2344/2344 - 5s - loss: 0.2833\n",
            "Epoch 477/500\n",
            "2344/2344 - 5s - loss: 0.2837\n",
            "Epoch 478/500\n",
            "2344/2344 - 4s - loss: 0.2905\n",
            "Epoch 479/500\n",
            "2344/2344 - 5s - loss: 0.3031\n",
            "Epoch 480/500\n",
            "2344/2344 - 4s - loss: 0.2855\n",
            "Epoch 481/500\n",
            "2344/2344 - 4s - loss: 0.2807\n",
            "Epoch 482/500\n",
            "2344/2344 - 4s - loss: 0.2946\n",
            "Epoch 483/500\n",
            "2344/2344 - 4s - loss: 0.2859\n",
            "Epoch 484/500\n",
            "2344/2344 - 4s - loss: 0.3347\n",
            "Epoch 485/500\n",
            "2344/2344 - 4s - loss: 0.2877\n",
            "Epoch 486/500\n",
            "2344/2344 - 4s - loss: 0.3049\n",
            "Epoch 487/500\n",
            "2344/2344 - 5s - loss: 0.2754\n",
            "Epoch 488/500\n",
            "2344/2344 - 4s - loss: 0.3158\n",
            "Epoch 489/500\n",
            "2344/2344 - 4s - loss: 0.3045\n",
            "Epoch 490/500\n",
            "2344/2344 - 4s - loss: 0.2830\n",
            "Epoch 491/500\n",
            "2344/2344 - 4s - loss: 0.2887\n",
            "Epoch 492/500\n",
            "2344/2344 - 4s - loss: 0.2833\n",
            "Epoch 493/500\n",
            "2344/2344 - 4s - loss: 0.2912\n",
            "Epoch 494/500\n",
            "2344/2344 - 4s - loss: 0.2999\n",
            "Epoch 495/500\n",
            "2344/2344 - 4s - loss: 0.2862\n",
            "Epoch 496/500\n",
            "2344/2344 - 5s - loss: 0.2993\n",
            "Epoch 497/500\n",
            "2344/2344 - 5s - loss: 0.3047\n",
            "Epoch 498/500\n",
            "2344/2344 - 5s - loss: 0.2657\n",
            "Epoch 499/500\n",
            "2344/2344 - 4s - loss: 0.3087\n",
            "Epoch 500/500\n",
            "2344/2344 - 4s - loss: 0.3110\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7ade0ff8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxEiKoPePrHL"
      },
      "source": [
        "Predicting on all data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58PIikBcKam2"
      },
      "source": [
        "scaled_input = np.reshape(input_tensor,(n_samples,int(n_bs*n_paths*n_features))) \n",
        "scaled_input = scaler.transform(scaled_input) # transforming all data\n",
        "scaled_input = np.reshape(scaled_input,(scaled_input.shape[0],n_bs,n_paths,n_features)) # reshaping for 2D-CNN\n",
        "pred_vals = model.predict(scaled_input) # predicting UAV positions\n",
        "\n",
        "\n",
        "# pred_train = model.predict(scaled_df)\n",
        "# scaled_test =scaler.transform(X_test)\n",
        "# scaled_test = np.reshape(scaled_test,(scaled_test.shape[0],n_bs,n_paths,n_features))\n",
        "# pred_test = model.predict(scaled_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd4I0pTRP5Xu"
      },
      "source": [
        "In case we need to calculate errors in training, testing, overall. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t2mWBSvKam3",
        "outputId": "99c56965-4227-4317-eb93-1862fa289105"
      },
      "source": [
        "print(X_test.shape)\n",
        "#pred_vals = scaler.inverse_transform(pred_vals)\n",
        "#pred_train = scaler.inverse_transform(pred_train)\n",
        "#pred_test = scaler.inverse_transform(pred_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(75000, 600)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kxHRFxLP6Yp"
      },
      "source": [
        "Calculating norm of the errors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS1C-nsIKam3"
      },
      "source": [
        "#pred_vals = outScaler.inverse_transform(pred_vals)\n",
        "norm_error = np.linalg.norm(pred_vals - true_cord_tensor,axis = 1)\n",
        "# norm_error_train = np.linalg.norm(pred_train - y_train,axis = 1)\n",
        "# norm_error_test = np.linalg.norm(pred_test - y_test,axis = 1)\n",
        "# print(norm_error.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj7LgnuCP8-0"
      },
      "source": [
        "Constructing CDFs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "xqaxOOBFKam4",
        "outputId": "c9d5afc6-d782-4b37-a74a-c45a7fcc2f0b"
      },
      "source": [
        "from statsmodels.distributions.empirical_distribution import ECDF\n",
        "\n",
        "cdf = ECDF(norm_error/1)\n",
        "plt.plot(cdf.x,cdf.y)\n",
        "plt.grid()\n",
        "plt.xlim([0,20])\n",
        "\n",
        "# cdf = ECDF(norm_error_train/1)\n",
        "# plt.plot(cdf.x,cdf.y)\n",
        "# plt.grid()\n",
        "# plt.xlim([0,20])\n",
        "\n",
        "\n",
        "# cdf = ECDF(norm_error_test/1)\n",
        "# plt.plot(cdf.x,cdf.y)\n",
        "# plt.grid()\n",
        "# plt.xlim([0,6])\n",
        "\n",
        "\n",
        "mat = scipy.io.loadmat('overall_DNN.mat')\n",
        "err_data = mat['norm_error']\n",
        "err_data = (err_data).flatten()\n",
        "cdf = ECDF(err_data*1)\n",
        "plt.plot(cdf.x,cdf.y)\n",
        "\n",
        "\n",
        "mat = scipy.io.loadmat('baselineerror.mat')\n",
        "err_data = mat['err_data']\n",
        "err_data = (err_data).flatten()\n",
        "cdf = ECDF(err_data*1)\n",
        "plt.plot(cdf.x,cdf.y)\n",
        "\n",
        "\n",
        "\n",
        "plt.xlabel('Error in meters')\n",
        "plt.ylabel('CDF')\n",
        "plt.legend(['CNN','NN','baseline'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7ad7f5cb90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWEGy8P0QALD"
      },
      "source": [
        "Mean error. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lePWwt2IKam4",
        "outputId": "d9e4b4a8-4c4f-42b7-f53b-20f1a24ba76d"
      },
      "source": [
        "print(np.mean(norm_error))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8542655097569396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG2Os-nzQFJj"
      },
      "source": [
        "80% intersection point on CDF. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlaB2iBjKam5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49d53a29-0e60-421e-961d-502b74f035a9"
      },
      "source": [
        "cdf = ECDF(norm_error/1)\n",
        "y = cdf.y\n",
        "indx = cdf.x[y>0.8]\n",
        "#print(\" {0}\":)\n",
        "print(\"The 80% percentile error in meters is \", indx[0], end='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The 80% percentile error in meters is  1.0207972544314752"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdDiJ-0RQI1h"
      },
      "source": [
        "Saving model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSZUdwZKaDlR",
        "outputId": "a6fa97ad-e81a-40f6-d38a-bf4b42045d9f"
      },
      "source": [
        "model.save('uav_localize_cnn_model_no_noise')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: uav_localize_cnn_model_no_noise/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FX8XU7fAaLIa",
        "outputId": "8249ed5b-d5ee-44e1-cd41-72c3146065de"
      },
      "source": [
        "!zip -r /content/uav_localize_cnn_model_no_noise.zip /content/uav_localize_cnn_model_no_noise"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/uav_localize_cnn_model_no_noise/ (stored 0%)\n",
            "  adding: content/uav_localize_cnn_model_no_noise/variables/ (stored 0%)\n",
            "  adding: content/uav_localize_cnn_model_no_noise/variables/variables.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/uav_localize_cnn_model_no_noise/variables/variables.index (deflated 64%)\n",
            "  adding: content/uav_localize_cnn_model_no_noise/saved_model.pb (deflated 88%)\n",
            "  adding: content/uav_localize_cnn_model_no_noise/assets/ (stored 0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLOMOpAxQLFT"
      },
      "source": [
        "Saving error array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sESfuM-cYd4W"
      },
      "source": [
        "scipy.io.savemat('2DCNN_no_noise_error.mat', {'norm_error':norm_error})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUsWJGTsQOcS"
      },
      "source": [
        "Checking error arrray."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkjMl5F5YozZ",
        "outputId": "782f6e7d-48f1-4da3-cb00-219f602db598"
      },
      "source": [
        "err = scipy.io.loadmat('2DCNN_no_noise_error.mat')\n",
        "err= err['norm_error']\n",
        "err = err.flatten()\n",
        "cdf = ECDF(err/1)\n",
        "y = cdf.y\n",
        "indx = cdf.x[y>0.8]\n",
        "#print(\" {0}\":)\n",
        "print(\"The 80% percentile error in meters is \", indx[0], end='')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The 80% percentile error in meters is  1.0207972544314752"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}